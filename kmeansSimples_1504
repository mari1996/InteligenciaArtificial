# -*- coding: utf-8 -*-
"""
Created on Sun Apr 15 12:44:23 2018

@author: Mariana
"""

#K-means implementado com distancia euclidiana

import pandas as pd
import numpy as np
import time
import datetime

#funcao criada para pegar o conteudo que esta dentro do excel passado
def pegaTexto (nome):   
    return pd.read_excel(nome, encoding = 'iso-8859-1')

def distanciaEuclidiana (vetor1, vetor2):  
    
    soma = np.sum((vetor1 - vetor2)**2)
    raiz = np.sqrt(soma)
    return raiz

#funcao kmeans
def kmeans(num_clusters, taxa_erro, num_linhas, num_colunas, vetor_dados, max_iteracoes):   
    #decidir se vai receber o numero de clusters como parametro ou se vai usar max cluster
    #decidir se vai receber a taxa de erro como parametro ou se vai usar a taxa de erro definida fora
        
    #criamos uma lista que vai guardar os centroides 
    #esses centroides vao ser inicializados de forma aleatoria
    centroides = vetor_dados[np.random.randint(0, num_linhas - 1, size=num_clusters)]
    
    #para podermos calcular o erro medio precisamos comparar a lista de centroides atuais com a lista anterior de centroides
    #essa lista é definida com o mesmo tamanho que a nossa lista de centroides
    #inicializamos esse vetor com 0s
    centroides_antigos = np.zeros(centroides.shape)
    
    #como cada dado vai pertencer a um cluster diferente, criamos uma lista que vai conter todos os dados e em quais
    #clusters eles vao estar
    #inicializamos esse vetor com 0s
    #vetor de dados x cluster
    dados_cluster = np.zeros((num_linhas, 1))
    
    #precisamos calcular a distancia entre os dois vetores de centroides, o antigo e o novo, para saber se diminuimos o erro ou nao
    #calculamos essa distancia usando a distancia euclidiana
    #se a distancia (ou erro) for menor que a taxa de erro passada, significa que nao precisamos mais calcular novos centroides
    distancia_centroides = distanciaEuclidiana(centroides, centroides_antigos)
    
    #guardamos o número de iterações pra não passarmos do máximo de iteracoes permitidas
    iteracoes = 0
    
    #vamos recalcular os centroides apenas se o erro ainda for maior do que a taxa permitida e se o numero maximo de iteracoes ainda 
    #nao foi alcancado
    #verificar se é or ou and aqui
    while iteracoes < max_iteracoes and distancia_centroides > taxa_erro:
        
        #a iteracao aumenta em 1
        iteracoes += 1
        
        #recalculamos a distancia
        distancia_centroides = distanciaEuclidiana(centroides, centroides_antigos)
        
        #como estamos numa nova iteracao, consideramos que os centroides atuais agora vao ser antigos
        #porque vamos recalcular a lista de centroides
        centroides_antigos = centroides
        
        #como vamos calcular os novos centroides precisamos saber a distancia de cada dado para cada centroide atual
        #para isso, criamos um vetor de distancias que vai guardar essas informacoes
        #a funcao enumerate enumera os dados que estamos vendo, nesse caso, os dados de vetor_dados
        #nesse caso, cada dado tera um indice proprio
        for indice_dado, dado in enumerate(vetor_dados):
            #definimos um vetor de tamanho num_clusters, pois temos num_clusters centroides que devem ser recalculados
            distancia_dados = np.zeros((num_clusters, 1))
            #para cada centroide que possuimos, precisamos calcular as distancias dos dados ate eles
            for indice_centroide, centroide in enumerate(centroides):
                #vamos calcular a distancia de cada dado ate cada centroide
                #as menores distancias vao mostrar onde os dados devem ficar
                distancia_dados[indice_centroide] = distanciaEuclidiana(centroide, dado)
                #essas distancias estao armazenadas num vetor distancia de dados X centroide
            #queremos identificar em qual cluster cada dado vai ficar
            #para isso, criamos uma lista contendo todos os dados e a qual cluster ele pertence (nessa iteracao)
            #dizemos que o dado X esta no cluster em que a distancia entre ele e o centroide N e a menor
            #a funcao np.argmin retorna o menor valor
            dados_cluster[indice_dado, 0] = np.argmin(distancia_dados)
        #criamos uma lista de centroides temporarios que sao atualizados dentro dessa iteracao para nao perdermos o que 
        #estamos calculando
        temp_centroides = np.zeros((num_clusters, num_colunas))
        
        #para cada cluster vamos encontrar todos os dados que estao mais proximos dele e vamos achar o ponto medio entre 
        #eles
        #esse ponto medio sera o valor do novo centroide
        for indice in range(len(centroides)):
            dados_proximos = [i for i in range(len(dados_cluster)) if dados_cluster[i] == indice]   
            
            #se o valor da distancia for zero, definir esse centroide novo como o centroide antigo
            
            #tratamos o caso do cluster ainda não ter dados próximos a ele
            #se o cluster ainda não possui dados proximos a ele, pulamos esse caso
            if dados_proximos == []:
                break
            
            #encontramos o valor medio desses dados proximos, que vai ser o nosso novo centroide
            #adicionar um if pra não entrar no caso de ser 0
            centroide = np.mean(vetor_dados[dados_proximos], axis=0)
            #acrescentamos o novo centroide na lista de centroides temporarios
            temp_centroides[indice, :] = centroide
            
        centroides = temp_centroides
           
    return centroides, dados_cluster, iteracoes

##################################################################################################################################

arquivo = 'C:/Users/Mariana/Desktop/IA/Saidas_teste/Process_Mining_Abstracts_TF.xlsx'

#a matriz dados vai guardar todo o conteudo lido do arquivo, inclusive os cabecalhos (documentos e palavras)
dados = pegaTexto(arquivo)

palavras = dados.axes[1].tolist()
documentos = dados.axes[0].tolist()

#a variavel "colunas" guarda a quantidade de colunas que existem no excel passado
colunas = dados.shape[1]

#a variavel "linhas" guarda a quantidade de linhas que existem no arquivo passado
linhas = dados.shape[0]

#o vetor conteudo guarda os valores numericos pegos no excel, ou seja, as aparicoes das palavras nos textos
conteudo = dados.values.tolist()

#esse vetor "valores" vai guardar todas as informacoes numericas que sao pegas no excel
#ou seja, esse vetor vai conter as aparicoes das palavras nos textos
valores = np.zeros((linhas, colunas))

a = 0
b = 0

#esse loop vai guardar os valores de conteudo em um outro vetor
#verificar se e realmente necessario criar essa matriz
while a < linhas:
    while b< colunas:
        valores[a][b] = conteudo[a][b]
        b+=1
    b = 1
    a+=1


#funcao que faz a escrita do log execucao
def escrita(arquivo_entrada, num_clusters, tempo_total, erro, docs, vetor_cluster, numArquivo, iteracoes):
    
    #essa funcao faz a escrita do log de execucao de cada chamada ao k-means e salva no seguinte formato:
    arquivo = open('C:/Users/Mariana/Desktop/IA/saidas/execucao'+str(numArquivo)+'.txt', 'w')
    
    now = datetime.datetime.now()
    
    arquivo.write('Execução feita em '+str(now.day)+'/'+str(now.month)+'/'+str(now.year)+' - '+str(now.hour)+':'+str(now.minute)+'\n')
    
    arquivo.write('\n')
    arquivo.write('Arquivo de entrada '+arquivo_entrada+'\n')
    arquivo.write('Numero de clusters: '+str(num_clusters)+'\n')
    arquivo.write('Tempo total de execução: '+str(tempo_total)+'\n')
    arquivo.write('Taxa de erro máxima permitida: '+str(erro)+'\n')
    arquivo.write('Total de iteracoes: '+str(iteracoes)+'\n')
    arquivo.write('Distância usada: euclidiana')
    arquivo.write('\n')
    arquivo.write('\n')
    
    #mandar qual documento ficou em cada cluster
    m = 0
    
    while m < len(docs):
        arquivo.write('Documento '+str(docs[m])+' - Cluster '+str(int(vetor_cluster.item(m)))+'\n')
        m += 1
    
    
    arquivo.close()
    
    return

##################################################################################################################################


#o execute fica aqui
#ele serve como um main que vai chamar varias vezes o kmeans, sempre variando os parametros usados    
def execute(clusters, erro, maxIter):

    
#    while k < maxIter:
#        
    start = time.time()

    centroides, dados_cluster, iteracoes = kmeans(clusters, erro, linhas, colunas, valores, maxIter)
    
    tempo_total = ("--- %s seconds ---" % (time.time() - start))
    
    escrita(arquivo, clusters,tempo_total,  erro, documentos, dados_cluster, 1, iteracoes)
    
      
    
    return


num_clusters = 10
taxa_erro = 0.0
max_iteracoes = 15

execute(num_clusters, taxa_erro, max_iteracoes)
